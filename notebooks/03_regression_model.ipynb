{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Módulos estándar de Python\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Manipulación de datos\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualización de datos\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Preprocesamiento y transformación de datos - Scikit-learn\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "# División de datos y validación cruzada - Scikit-learn\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, learning_curve\n",
    "\n",
    "# Encoders para variables categóricas\n",
    "import category_encoders as ce\n",
    "from category_encoders import TargetEncoder\n",
    "\n",
    "# Modelos de regresión - Scikit-learn\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.svm import SVR, NuSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor,\n",
    "    GradientBoostingRegressor,\n",
    "    ExtraTreesRegressor,\n",
    "    HistGradientBoostingRegressor,\n",
    "    BaggingRegressor,\n",
    "    AdaBoostRegressor\n",
    ")\n",
    "\n",
    "# Redes neuronales - Scikit-learn\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Modelos de boosting\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Distribuciones para búsqueda de hiperparámetros\n",
    "from scipy.stats import uniform, randint\n",
    "\n",
    "# Métricas de evaluación - Scikit-learn\n",
    "from sklearn.metrics import (\n",
    "    r2_score,\n",
    "    mean_absolute_error,\n",
    "    root_mean_squared_error,\n",
    "    root_mean_squared_log_error,\n",
    "    make_scorer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de funciones personalizadas desde el directorio 'src'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "from regression_model import feature_importances, graficar_curva_aprendizaje_rmsle, calcular_metricas_rendimiento, revisar_predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos de Regresión para la Predicción de **SalePrice**\n",
    "\n",
    "Para la construcción de los modelos de regresión, se utilizó el conjunto de **train**, ya que el conjunto **test** no contiene valores en la variable objetivo (*target*), lo que impide evaluar el rendimiento del modelo directamente con las métricas.\n",
    "\n",
    "Los datos fueron divididos en dos conjuntos: **train** y **validación**. Además, se empleó validación cruzada para obtener una evaluación más robusta y precisa del rendimiento del modelo.\n",
    "\n",
    "Las predicciones generadas, `y_pred`, fueron comparadas con los valores reales, `y_val`, para evaluar el desempeño del modelo utilizando diversas métricas. Este proceso permitió identificar áreas de mejora, como ajustar el preprocesamiento de los datos o la selección de variables.\n",
    "\n",
    "Se probaron varios modelos de regresión y se ajustaron hasta encontrar el que ofreciera las predicciones más cercanas a los valores reales. Finalmente, tras alcanzar un nivel de precisión satisfactorio, se aplicó el modelo al conjunto de datos de **test** y los resultados se guardaron en un archivo **.csv**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos de entrenamiento y prueba desde archivos pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_pickle('../data/train.pkl')\n",
    "test= pd.read_pickle('../data/test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminación de Columnas para los Modelos\n",
    "\n",
    "Este procedimiento describe la eliminación de columnas del conjunto de datos basándose en las **importancias de características** (*feature importances*) menos relevantes. El objetivo principal es simplificar el modelo, eliminando aquellas columnas que no aportan valor significativo o que podrían impactar negativamente en su desempeño.  \n",
    "\n",
    "El proceso se aplica de manera consistente en ambos subconjuntos de datos (entrenamiento y prueba) para garantizar que se mantengan alineados.\n",
    "\n",
    "Las columnas que aparecen en esta lista, denominada `columnas_eliminar`, son el resultado del último modelo, lo que implica que podrían no ser las mismas que beneficiarían a otros modelos.\n",
    "\n",
    "- **Columnas revisadas pero no eliminadas**:  \n",
    "  Algunas columnas inicialmente clasificadas como poco relevantes se conservan tras comprobar que su eliminación empeora el modelo. Estas características pueden tener un impacto indirecto en el rendimiento del modelo.\n",
    "\n",
    "```python\n",
    "EnclosedPorch, LandContour, Foundation, MoSold, Street, LotShape, Neighborhood, ExterQual, ExterCond, 1stFlrSF, 2ndFlrSF, CentralAir, MasVnrType, MasVnrArea, BsmtHalfBath, Antigüedad_Remodelacion, TieneSotano.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_eliminar = [\n",
    "    \"3SsnPorch\",\n",
    "    \"Alley\",\n",
    "    \"Antiguedad\",\n",
    "    \"BañosTotales\",\n",
    "    \"BedroomAbvGr\",\n",
    "    \"BldgType\",\n",
    "    \"BsmtFinSF2\",\n",
    "    \"BsmtFinType2\",\n",
    "    \"BsmtUnfSF\",\n",
    "    \"Electrical\",\n",
    "    \"Fence\",\n",
    "    \"HasFireplaces\",\n",
    "    \"HasGarage\",\n",
    "    \"HasShed\",\n",
    "    \"Heating\",\n",
    "    \"HouseStyle\",\n",
    "    \"KitchenAbvGr\",\n",
    "    \"LandSlope\",\n",
    "    \"LotConfig\",\n",
    "    \"LowQualFinSF\",\n",
    "    \"MiscVal\",\n",
    "    \"NumeroSotanos\",\n",
    "    \"PoolArea\",\n",
    "    \"PoolQC\",\n",
    "    \"RoofMatl\",\n",
    "    \"RoofStyle\",\n",
    "    \"SaleType\",\n",
    "    \"ScreenPorch\",\n",
    "    \"TienePiscina\",\n",
    "    \"YrSold\",\n",
    "]\n",
    " \n",
    "train.drop(columns=columnas_eliminar, inplace=True)\n",
    "test.drop(columns=columnas_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## División del conjunto de datos de train\n",
    "Se define la target y las características X, se elimina Id ya que no es útil para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['SalePrice', 'Id'], axis=1)\n",
    "y = train['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificación de Variables para Transformación Logarítmica \n",
    "\n",
    "En este proceso se identificaron las variables que podían beneficiarse de la aplicación de una transformación logarítmica, incluyendo la variable objetivo (precios de las casas). Esta transformación fue implementada en los modelos con la teoría de mejorar su desempeño.\n",
    "\n",
    "En problemas donde las variables presentan un amplio rango de valores (por ejemplo, precios de casas que varían desde $50,000 hasta varios millones de dólares), los valores grandes pueden dominar el modelo y reducir la precisión de las predicciones. La transformación logarítmica permite reducir este efecto, equilibrando el impacto de los valores extremos y mejorando el rendimiento general del modelo.\n",
    "\n",
    "Algunas variables, como los precios de las casas, presentan **distribuciones sesgadas**, con pocos valores extremadamente altos y una gran cantidad de valores pequeños. Al aplicar un logaritmo, los valores grandes se \"acortan\", lo que ayuda a que la distribución se aproxime a una forma más normal o simétrica.\n",
    "\n",
    "Tras evaluar el modelo final `XGBRegressor` aplicando al conjunto de esas variables la transformación, se comprueba que la única variable que se ve beneficiada de esta transformación logarítmica es `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_logaritmo = [\n",
    "    'LotArea', 'LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'TotalBsmtSF', 'EnclosedPorch', \n",
    "    '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación del Modelo de Validación mediante la Comparación Inicial de Múltiples Modelos\n",
    "\n",
    "# Modelos Seleccionados para la Prueba Inicial  \n",
    "\n",
    "En la etapa inicial de pruebas, los modelos fueron divididos en dos grupos, dependiendo de si se benefician o no del escalado de las características\n",
    "\n",
    "Modelos como `XGBRegressor`, `RandomForestRegressor`, `GradientBoostingRegressor`, `DecisionTreeRegressor`, `LGBMRegressor`, `CatBoostRegressor`, `BaggingRegressor`, o `AdaBoostRegressor` pueden entrenarse **sin necesidad de escalado** de las características. Esto se debe a que estos algoritmos, en su mayoría basados en árboles, utilizan divisiones en función de umbrales y no dependen de magnitudes absolutas o distancias.  \n",
    "\n",
    "Por otro lado, hay modelos como `LinearRegression`, `Lasso`, `Ridge`, `SVR` o `KNeighborsRegressor`, que **dependen del escalado** de las características para funcionar correctamente. En estos casos, es fundamental que todas las variables tengan una escala similar para garantizar un buen desempeño.  \n",
    "\n",
    "Se identificó que los **modelos que no requieren escalado** de las variables tienden a obtener mejores resultados en las pruebas iniciales. Esto podría deberse a que dichos modelos son menos sensibles a las distribuciones y escalas de las características, lo que los hace más robustos en diversas configuraciones de datos.  \n",
    "\n",
    "### Validación cruzada\n",
    "\n",
    "Se opta por hacer **validación cruzada** en lugar de una división fija del conjunto de datos en entrenamiento y validación. Con la validación cruzada, se puede obtener una evaluación más robusta del modelo al entrenarlo y validarlo en múltiples subdivisiones del conjunto de datos.\n",
    "\n",
    "Se utilizó una validación cruzada con **10 divisiones** (*10-fold cross-validation*). Esto implica que el conjunto de datos se divide en 10 partes, y el modelo se entrena en 9 de ellas mientras se valida en la restante, repitiendo este proceso 10 veces, para mayor fiabilidad en la estimación del desempeño del modelo.  \n",
    "\n",
    "### RMSLE como métrica de referencia de mejora del modelo\n",
    "\n",
    "Para evaluar el rendimiento del modelo, se utilizó la métrica RMSLE, el Error Cuadrático Medio Logarítmico. Esta métrica fue elegida porque es la que utiliza Kaggle en la competición, y es especialmente útil cuando hay una gran variabilidad en los precios de las casas.\n",
    "\n",
    "Esta métrica enfoca la evaluación en el porcentaje de error en lugar de solo medir la diferencia absoluta entre las predicciones y los valores reales. En problemas como el de precio de casas, donde los valores pueden variar enormemente (por ejemplo, de $50,000 a $5,000,000), RMSLE ayuda a manejar esta gran variabilidad de manera más efectiva.\n",
    "\n",
    "Aunque RMSLE es la métrica principal, también se emplearon otras métricas para evaluar el modelo de manera más completa. Si el ajuste del modelo provocaba una mejora en RMSLE pero deterioraba otras métricas clave, como R² (Coeficiente de determinación),  esos cambios no se mantenían, ya que el objetivo es lograr un buen equilibrio entre todas las métricas.\n",
    "\n",
    "### Transformación de variables\n",
    "\n",
    "En algunos modelos se aplicó logaritmo a algunas variables, incluida la target, para manejar su distribución sesgada. Los precios tienen pocos valores grandes y muchos pequeños, y al aplicar el logaritmo, los valores más grandes se \"acortan\", ayudando a que la distribución sea más simétrica. Esto evita que los valores extremos dominen el modelo y mejora la precisión en las predicciones.\n",
    "\n",
    "### Evaluación de Escaladores\n",
    "Para los modelos que se benefician del escalado, se prueba también **StandardScaler**, en lugar de **MinMaxScaler**, pero se observa un ligero **empeoramiento**.\n",
    "\n",
    "### Preparación de los datos\n",
    "\n",
    "Se separan las **características** `X` y la **variable objetivo** `y` y se realiza la división del conjunto de datos original en dos subconjuntos:\n",
    "\n",
    "- **Conjunto de entrenamiento `X_train`, `y_train`**: Utilizado para entrenar el modelo.\n",
    "- **Conjunto de validación `X_val`, `y_val`**: Utilizado para evaluar el rendimiento del modelo antes de aplicar todo train a datos no vistos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos que requieren escalado  \n",
    "\n",
    "Se aplicó primero una transformación logarítmica a los datos y luego un escalado. Para revertir estas transformaciones, se deshizo primero el escalado y, posteriormente, se aplicó la operación inversa del logaritmo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_finales = []\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista de modelos a evaluar\n",
    "modelos = [\n",
    "    LinearRegression(),\n",
    "    Lasso(random_state=42),\n",
    "    Ridge(random_state=42),\n",
    "    SVR(),\n",
    "    KNeighborsRegressor(),\n",
    "    ElasticNet(random_state=42),\n",
    "    KNeighborsRegressor(),\n",
    "    NuSVR()\n",
    "]\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for modelo in modelos:\n",
    "    resultados_modelo = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train = (y.iloc[train_index] + 1).apply(np.log)  # Aplica logaritmo a las etiquetas\n",
    "        y_val = (y.iloc[val_index] + 1).apply(np.log)\n",
    "\n",
    "        # Aplica logaritmo a las columnas seleccionadas de X_train y X_val\n",
    "        X_train.loc[:, columnas_logaritmo] = X_train[columnas_logaritmo].apply(lambda col: np.log1p(col))  # log(x + 1)\n",
    "        X_val.loc[:, columnas_logaritmo] = X_val[columnas_logaritmo].apply(lambda col: np.log1p(col))  # log(x + 1)\n",
    "\n",
    "        # Escalar las características (X_train y X_val)\n",
    "        x_scaler = MinMaxScaler()\n",
    "        X_train = x_scaler.fit_transform(X_train)\n",
    "        X_val = x_scaler.transform(X_val)\n",
    "\n",
    "        # Escalar las etiquetas (y_train y y_val)\n",
    "        y_scaler = MinMaxScaler()\n",
    "        y_train = y_scaler.fit_transform(y_train.values.reshape(-1, 1)).ravel()\n",
    "        y_val = y_scaler.transform(y_val.values.reshape(-1, 1)).ravel()\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        # Hacer predicciones\n",
    "        yhat = modelo.predict(X_val)\n",
    "\n",
    "        # Revertir el escalado de las predicciones y etiquetas primero\n",
    "        yhat = y_scaler.inverse_transform(yhat.reshape(-1, 1))  # Revertir escalado de las predicciones\n",
    "        y_val = y_scaler.inverse_transform(y_val.reshape(-1, 1))  # Revertir escalado de las etiquetas reales\n",
    "\n",
    "        # Y luego revertir el logaritmo en las predicciones\n",
    "        yhat = np.exp(yhat) - 1  \n",
    "        y_val = np.exp(y_val) - 1  \n",
    "\n",
    "        # Llamar a la función calcular_metricas_rendimiento\n",
    "        df_metricas = calcular_metricas_rendimiento(modelo, X_val, y_val, yhat)\n",
    "\n",
    "        # Extraer las métricas desde el DataFrame devuelto\n",
    "        r2, mae, rmse, mse, rmsle = df_metricas.iloc[0, 1:].values\n",
    "\n",
    "        resultados_modelo.append([modelo.__class__.__name__, r2, mae, rmse, mse, rmsle])\n",
    "\n",
    "    # Guardar resultados del modelo\n",
    "    resultados_finales.extend(resultados_modelo)\n",
    "\n",
    "# Crear un DataFrame para los resultados finales\n",
    "resultados_df = pd.DataFrame(resultados_finales, columns=['Modelo', 'R2', 'MAE', 'RMSE', 'MSE', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una función para evaluar la precisión de los modelos, priorizando aquellos con un menor RMSLE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df_ordenados = resultados_df.sort_values(by='RMSLE')\n",
    "\n",
    "resultados_df_ordenados.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos que no requieren escalado  \n",
    "\n",
    "En general, los modelos que no requieren escalado de las variables obtienen mejores resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para almacenamiento de resultados\n",
    "resultados_finales = []\n",
    "\n",
    "# Se guardan las mejores particiones para graficar luego las feature y la curva de aprendizaje\n",
    "mejor_rmsle = float('inf')  # Inicialmente, algo muy alto para buscar el mínimo\n",
    "mejor_particion = None      # Aquí se guardarán los índices de la mejor partición\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Lista de modelos a evaluar\n",
    "modelos = [\n",
    "    XGBRegressor(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    LGBMRegressor(random_state=42, verbose=-1),  \n",
    "    CatBoostRegressor(random_state=42),\n",
    "    BaggingRegressor(random_state=42),\n",
    "    AdaBoostRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42),\n",
    "    HistGradientBoostingRegressor(random_state=42),\n",
    "]\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for modelo in modelos:\n",
    "    resultados_modelo = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train = (y.iloc[train_index] + 1).apply(np.log)\n",
    "        y_val = (y.iloc[val_index] + 1).apply(np.log)\n",
    "\n",
    "    # Aplica logaritmo a las columnas seleccionadas de X_train y X_val\n",
    "        X_train.loc[:, columnas_logaritmo] = X_train[columnas_logaritmo].apply(lambda col: np.log(col + 1))\n",
    "        X_val.loc[:, columnas_logaritmo] = X_val[columnas_logaritmo].apply(lambda col: np.log(col + 1))\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        # Hacer predicciones\n",
    "        yhat = modelo.predict(X_val)\n",
    "\n",
    "        # Invertir logaritmo de las predicciones\n",
    "        yhat = np.exp(yhat) - 1\n",
    "        y_val = np.exp(y_val) - 1\n",
    "\n",
    "        # Llamar a la función calcular_metricas_rendimiento\n",
    "        df_metricas = calcular_metricas_rendimiento(modelo, X_val, y_val, yhat)\n",
    "\n",
    "        # Extraer las métricas desde el DataFrame devuelto\n",
    "        r2, mae, rmse, mse, rmsle = df_metricas.iloc[0, 1:].values\n",
    "\n",
    "        resultados_modelo.append([modelo.__class__.__name__, r2, mae, rmse, mse, rmsle])\n",
    "\n",
    "        # Si este RMSLE es el mejor (más bajo), guardar los índices (se hace para luego graficar las features y la curva de aprendizaje)\n",
    "        if rmsle < mejor_rmsle:\n",
    "            mejor_rmsle = rmsle\n",
    "            mejor_particion = (train_index, val_index)\n",
    "\n",
    "    # Guardar resultados del modelo\n",
    "    resultados_finales.extend(resultados_modelo)\n",
    "\n",
    "resultados_df = pd.DataFrame(resultados_finales, columns=['Modelo', 'R2', 'MAE', 'RMSE', 'MSE', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas de Evaluación del Modelo  \n",
    "\n",
    "- **R² (Coeficiente de determinación):** Mide qué tan bien el modelo predice los datos. Indica el porcentaje de la variabilidad de los precios que el modelo es capaz de explicar. Si **R²** es cercano a 1, significa que el modelo está explicando bien la variabilidad en los datos.\n",
    "\n",
    "- **Error Absoluto Medio (MAE):** Mide el promedio de los errores absolutos entre las predicciones y los valores reales. Por ejemplo, si el **MAE** es $7,500, significa que, en promedio, el modelo se equivoca por esa cantidad. Es una medida directa de la magnitud de los errores sin tener en cuenta su dirección (positivo o negativo).\n",
    "\n",
    "- **RMSE (Root Mean Squared Error):** Es la raíz cuadrada del Error Cuadrático Medio (**MSE**), lo que penaliza más los errores grandes. Si el **RMSE** es más alto que el **MAE** (por ejemplo, $10,000 en lugar de $7,500), eso indica que hay errores grandes que están afectando más al modelo debido a la naturaleza cuadrática de esta métrica. Los errores más grandes tienen más peso en el **RMSE**.\n",
    "\n",
    "- **MSE (Mean Squared Error):** Es el Error Cuadrático Medio, similar al **RMSE** pero sin tomar la raíz cuadrada. Al elevar los errores al cuadrado, el **MSE** amplifica los errores más grandes. Por ejemplo, si el **MSE** es $100,000,000, significa que hay errores muy grandes que están influyendo en la evaluación, ya que el **MSE** amplifica estos errores.\n",
    "\n",
    "- **RMSLE (Root Mean Squared Logarithmic Error):** Es útil cuando la escala de las predicciones y los valores reales varía en orden de magnitud (como en el caso de los precios de las casas). El **RMSLE** bajo (por ejemplo, 0.05) indica que las predicciones son bastante precisas en relación con las variaciones de precio, incluso si los valores reales tienen una gran diferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ordena el DataFrame por la columna **RMSLE** de menor a mayor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df_ordenados = resultados_df.sort_values(by='RMSLE')\n",
    "\n",
    "resultados_df_ordenados.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mejor modelo inicial\n",
    "\n",
    "Tras realizar la validación cruzada, el modelo que inicialmente obtuvo el mejor rendimiento fue el *Random Forest Regressor*. Sin embargo, tras una nueva revisión del EDA y la limpieza de variables, el mejor desempeño lo presentó *LGBMRegressor*.  \n",
    "\n",
    "Es importante señalar que esta evaluación está sesgada, ya que se realizó sobre el conjunto de entrenamiento y validación. Esto significa que los resultados pueden no reflejar el comportamiento del modelo en datos no vistos, es decir, en el conjunto de prueba. Por esta razón, en la carpeta *outputs* se encuentran las predicciones de ambos modelos. Posteriormente, esta hipótesis se confirmó, lo que llevó a la selección final de *XGBRegressor*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_rmsle = resultados_df_ordenados['RMSLE'].min()\n",
    "mejor_modelo_fila = resultados_df_ordenados[resultados_df_ordenados['RMSLE'] == min_rmsle]\n",
    "\n",
    "index_mejor_modelo = mejor_modelo_fila.index[0] \n",
    "nombre_mejor_modelo = resultados_df.loc[index_mejor_modelo, 'Modelo']\n",
    "\n",
    "print(\"Mejor modelo:\", nombre_mejor_modelo)\n",
    "print(\"RMSLE del modelo replicado en el mejor fold:\", min_rmsle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observaciones de los resultados del modelo **LGBMRegressor**  \n",
    "\n",
    "- El valor de **R²** es **0.970214**, lo que indica que el modelo es capaz de explicar una gran parte de la variabilidad de los datos.  \n",
    "\n",
    "- El **MAE** es de **8,558.51**, lo que significa que el modelo se equivoca en promedio en aproximadamente **$8,558** en términos absolutos.  \n",
    "\n",
    "- **RMSE (Root Mean Squared Error):**  \n",
    "  - El valor de **RMSE** es **12,617.78**. Como es mayor que el **MAE**, indica la presencia de algunos errores más grandes en ciertas predicciones, aunque el rendimiento global del modelo sigue siendo sólido.  \n",
    "\n",
    "- El **MSE** es **1.59e+08**, lo cual es consistente con el **RMSE**, ya que ambas métricas están relacionadas.  \n",
    "\n",
    "- El **RMSLE** es **0.0654**, un valor relativamente bajo, lo que sugiere que las predicciones están bien alineadas con los valores reales en términos logarítmicos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_rf = resultados_df.query('Modelo == \"LGBMRegressor\"').sort_values(by='RMSLE')\n",
    "resultados_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Descripción de las estadísticas del modelo **LGBMRegressor**  \n",
    "\n",
    "El **promedio de RMSLE** es **0.109**, lo que indica el rendimiento medio del modelo en los diferentes *folds* de la validación cruzada. Esto sugiere que las predicciones del modelo son bastante precisas en relación con la variabilidad de los valores reales.  \n",
    "\n",
    "En promedio, el modelo ha logrado una diferencia moderada entre los valores reales y las predicciones en cada uno de los subconjuntos de validación. Dado que este valor sigue siendo relativamente bajo, indica que el modelo funciona bien en general y que las predicciones están razonablemente alineadas con los valores reales.  \n",
    "\n",
    "La **desviación estándar del RMSLE**, de **0.025**, mide la variabilidad o dispersión del **RMSLE** en los distintos *folds* de la validación cruzada. Esto indica cuán consistentes son las predicciones del modelo a lo largo de los diferentes subconjuntos de datos. En este caso, el modelo ha mantenido un rendimiento relativamente constante en todos los *folds*, lo que es una buena señal de que generaliza bien y no está sobreajustado a un subconjunto específico de los datos.  \n",
    "\n",
    "Un **promedio bajo de RMSLE**, combinado con una **desviación estándar baja**, sugiere que el modelo está realizando predicciones precisas y consistentes en las diferentes particiones del conjunto de datos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticas = resultados_rf[['R2', 'MAE', 'RMSE', 'MSE', 'RMSLE']].describe()\n",
    "estadisticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras probar varios modelos y ajustar sus hiperparámetros sin obtener los resultados deseados, se decidió optar por otro enfoque. No obstante, se dejan las conclusiones de algunos modelos como referencia.\n",
    "\n",
    "### Conclusiones **Random Forest Regressor**\n",
    "\n",
    "Aunque **Random Forest Regressor** mostró buenos resultados en el entrenamiento, presentó limitaciones al predecir en el conjunto de test. Tiende a no predecir valores fuera del rango observado, lo cual es problemático con variables continuas y dispersas como `SalePrice`. Además, el modelo puede sobreajustarse a patrones ruidosos. Aunque el **logaritmo** mejoró los resultados en la validación, su utilidad en datos no vistos aún debe evaluarse. La eliminación de **feature importances** menos relevantes mejoró la eficiencia, pero los resultados aún están basados en los datos de entrenamiento, lo que puede afectar el rendimiento en datos no vistos.\n",
    "\n",
    "### Conclusiones **ExtraTreesRegressor**\n",
    "\n",
    "- **Captura de valores extremos:** El modelo tiene dificultades para predecir los valores más altos de **SalePrice**, lo que sugiere que mejorar la captura de variaciones extremas podría ser clave.\n",
    "- **Ajuste de hiperparámetros:** La optimización de los hiperparámetros podría mejorar el rendimiento, especialmente en la predicción de valores atípicos.\n",
    "- **Pruebas con otros modelos:** Aunque **ExtraTreesRegressor** tiene un rendimiento razonable, modelos como **XGBoost** o **LightGBM** suelen obtener mejores resultados en este tipo de retos debido a su capacidad para manejar datos complejos.\n",
    "- **Cambio de codificación de variables:** Experimentar con diferentes métodos de codificación y perfeccionar la **codificación ponderada** puede mejorar la precisión de las predicciones.\n",
    "- **Revisión de features eliminadas:** Algunas variables eliminadas podrían ser útiles si se les da un tratamiento adecuado, mientras que otras podrían eliminarse para simplificar el modelo.\n",
    "- **Revisión de transformaciones logarítmicas:** Evaluar si algunas variables asimétricas podrían beneficiarse de una transformación logarítmica para mejorar el ajuste del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de un nuevo Modelo para la Predicción de SalePrice en Kaggle\n",
    "\n",
    "El cambio de enfoque para predecir `SalePrice` en Kaggle ha mejorado las predicciones, aunque el modelo aún tiene dificultades con los valores más altos debido a la distribución sesgada de los precios. Se implementará una nueva estrategia para mejorar las predicciones en el rango alto de precios.\n",
    "\n",
    "### Estrategia para Mejorar las Predicciones:\n",
    "\n",
    "1. **Ponderación de Errores:** Se asigna mayor peso a los errores cometidos en los valores altos de `SalePrice` durante el cálculo de las métricas, lo que ajusta el modelo para mejorar la predicción de esos valores.\n",
    "  \n",
    "2. **Ponderación en las Métricas:** Durante la validación cruzada, las métricas de error se ajustan para que los valores altos tengan mayor influencia en la evaluación, utilizando pesos dinámicos basados en `SalePrice`.\n",
    "\n",
    "3. **Uso del Percentil 75 de `SalePrice`:** Los valores por encima del percentil 75 se consideran \"valores altos\" y reciben mayor peso en la evaluación.\n",
    "\n",
    "4. **Aplicación de Logaritmos:** Se aplican transformaciones logarítmicas a la variable objetivo y características seleccionadas para reducir la asimetría en la distribución de `SalePrice` y mejorar las predicciones.\n",
    "\n",
    "### Implementación del Modelo con Ponderación de Errores:\n",
    "\n",
    "1. **División en Particiones:** Se usa validación cruzada (10 particiones) para entrenar y evaluar el modelo.\n",
    "\n",
    "2. **Entrenamiento de Modelos:** Se entrenan modelos como **XGBRegressor**, **RandomForestRegressor**, y **LGBMRegressor**, aplicando las transformaciones necesarias.\n",
    "\n",
    "3. **Evaluación con Ponderación:** Las métricas de rendimiento se calculan con ponderación para priorizar los errores en valores altos.\n",
    "\n",
    "4. **Selección del Mejor Modelo:** El modelo con el **RMSLE ponderado más bajo** se selecciona como el mejor.\n",
    "\n",
    "### Beneficios de la Estrategia:\n",
    "\n",
    "- **Mejora en la Predicción de Valores Altos:** La estrategia ajusta el modelo para predecir mejor los valores altos de `SalePrice`, mejorando el rendimiento en áreas clave.\n",
    "  \n",
    "- **Optimización para Kaggle:** Dado que las competiciones de Kaggle premian la precisión en los valores altos, este enfoque mejora la puntuación.\n",
    "\n",
    "- **Mayor Robustez:** La ponderación dinámica y la transformación logarítmica hacen el modelo más robusto frente a la distribución sesgada de los datos, lo que puede mejorar su generalización.\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "Con la nueva **estrategia de ponderación de errores**, se espera mejorar las predicciones de `SalePrice` en Kaggle, especialmente en los valores altos, y optimizar la puntuación en la competencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para almacenamiento de resultados\n",
    "resultados_finales = []\n",
    "\n",
    "# Se guardan las mejores particiones para graficar luego las feature y la curva de aprendizaje\n",
    "mejor_rmsle = float('inf')  # Inicialmente, algo muy alto para buscar el mínimo\n",
    "mejor_particion = None      # Aquí se guardarán los índices de la mejor partición\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Obtener el percentil 75 de SalePrice para usarlo como umbral para los valores altos\n",
    "percentil_75 = train['SalePrice'].quantile(0.75)\n",
    "\n",
    "# Lista de modelos a evaluar\n",
    "modelos = [\n",
    "    XGBRegressor(random_state=42),\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    GradientBoostingRegressor(random_state=42),\n",
    "    DecisionTreeRegressor(random_state=42),\n",
    "    LGBMRegressor(random_state=42, verbose=-1),  \n",
    "    CatBoostRegressor(random_state=42),\n",
    "    BaggingRegressor(random_state=42),\n",
    "    AdaBoostRegressor(random_state=42),\n",
    "    ExtraTreesRegressor(random_state=42),\n",
    "    HistGradientBoostingRegressor(random_state=42),\n",
    "]\n",
    "\n",
    "# Evaluar cada modelo\n",
    "for modelo in modelos:\n",
    "    resultados_modelo = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train = (y.iloc[train_index] + 1).apply(np.log)\n",
    "        y_val = (y.iloc[val_index] + 1).apply(np.log)\n",
    "\n",
    "        # Entrenar el modelo\n",
    "        modelo.fit(X_train, y_train)\n",
    "\n",
    "        # Hacer predicciones\n",
    "        yhat = modelo.predict(X_val)\n",
    "\n",
    "        # Invertir logaritmo de las predicciones\n",
    "        yhat = np.exp(yhat) - 1\n",
    "        y_val = np.exp(y_val) - 1\n",
    "\n",
    "        # Calcular el error ponderado (dar más peso a los valores más altos)\n",
    "        # Puedes hacer esto calculando el RMSLE ponderado por el valor de la verdad observada\n",
    "        ponderacion = y_val / y_val.max()  # Ponderar más los valores altos\n",
    "\n",
    "        r2 = r2_score(y_val, yhat)  # R²: Coeficiente de determinación\n",
    "        mae = mean_absolute_error(y_val, yhat)  # MAE: Error absoluto medio\n",
    "        rmse = root_mean_squared_error(y_val, yhat)  # RMSE: Raíz del error cuadrático medio\n",
    "        mse = rmse ** 2  # MSE: Error cuadrático medio\n",
    "        rmsle = root_mean_squared_log_error(y_val, yhat)  # RMSLE: Error cuadrático medio logarítmico\n",
    "\n",
    "        # Almacenar los resultados para este modelo\n",
    "        resultados_modelo.append([modelo.__class__.__name__, r2, mae, rmse, mse, rmsle])\n",
    "\n",
    "        # Si este RMSLE ponderado es el mejor, guardar los índices de la partición\n",
    "        if rmsle < mejor_rmsle:\n",
    "            mejor_rmsle = rmsle\n",
    "            mejor_particion = (train_index, val_index)\n",
    "\n",
    "    # Guardar resultados del modelo\n",
    "    resultados_finales.extend(resultados_modelo)\n",
    "\n",
    "# Guardar los resultados en un DataFrame\n",
    "resultados_df = pd.DataFrame(resultados_finales, columns=['Modelo', 'R2', 'MAE', 'RMSE', 'MSE', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al aplicar el nuevo método de selección de modelo para la predicción de **SalePrice** en Kaggle, basado en la optimización del rendimiento en los valores más altos, se ha observado que el modelo **XGBRegressor** es el que se posiciona como el mejor, de acuerdo con los resultados obtenidos en las distintas particiones de validación.\n",
    "\n",
    "No es de sorprender, puesto que, como ya se mencionaba anteriormente en las conclusiones del modelo **ExtraTreesRegressor**, en este reto los participantes suelen obtener mejores resultados con modelos como **XGBoost**. Esto se debe a que **XGBoost** es un modelo basado en **gradient boosting**, que tiene la capacidad de ajustar los errores de manera secuencial, mejorando su rendimiento en comparación con otros modelos como **Random Forest** o **Extra Trees**, que están basados en **bagging**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección final y ajuste del modelo **XGBRegressor**\n",
    "Tras haber encontrado el mejor modelo con predicciones bastante competitivas y tras revisar la curva de aprendizaje y explorar la eliminación de las feature menos importantes y tratar las más, se decide seguir optimizando el rendimiento del modelo.\n",
    "\n",
    "Se determinó que el **XGBRegressor** ofrecía el mejor desempeño en términos de **RMSLE**, que es la métrica prioritaria en este análisis. A continuación, se llevan a cabo las técnicas de ajuste de hiperparámetros **Randomized Search** y **Grid Search**, con el objetivo de mejorar los resultados. Estas son dos de las técnicas más populares y efectivas para encontrar la mejor combinación de hiperparámetros y mejorar el rendimiento de los modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Extracción de hiperparámetros de XGBRegressor**\n",
    "\n",
    "Se extraen los hiperparámetros que tiene XGBRegressor para decidir cuáles se van a optimizar:\n",
    "\n",
    "- **objective**: Define la función objetivo del modelo. En este caso, se utiliza `reg:squarederror`, que es la función estándar para regresión, orientada a minimizar el error cuadrático medio (MSE).\n",
    "- **base_score**: Valor inicial para todas las predicciones. Si es `None`, el valor se ajustará automáticamente.\n",
    "- **booster**: Especifica el tipo de booster a usar. Puede ser `gbtree`, `gblinear` o `dart`. Si es `None`, se seleccionará el valor predeterminado.\n",
    "- **callbacks**: Permite especificar una lista de funciones de devolución de llamada para modificar el comportamiento del modelo durante el entrenamiento. Por defecto es `None`.\n",
    "- **colsample_bylevel**: Fracción de columnas a utilizar por cada nivel del árbol. Si es `None`, se usa el valor predeterminado.\n",
    "- **colsample_bynode**: Similar a `colsample_bylevel`, pero se aplica a cada nodo. Deja este parámetro como `None` si no se desea modificarlo.\n",
    "- **colsample_bytree**: Fracción de columnas a seleccionar para construir cada árbol. Un valor de `None` implica que se utilizará el valor predeterminado.\n",
    "- **device**: Define el dispositivo en el que se entrenará el modelo, como `cpu` o `gpu`. Si se deja como `None`, se usará el valor por defecto.\n",
    "- **early_stopping_rounds**: Número de rondas de validación sin mejora para detener el entrenamiento. Si es `None`, no se utiliza esta funcionalidad.\n",
    "- **enable_categorical**: Si es `True`, permite que el modelo maneje características categóricas. Se deja como `False` por defecto.\n",
    "- **eval_metric**: Métrica a utilizar para la evaluación. Si es `None`, se calculará una métrica predeterminada.\n",
    "- **feature_types**: Define el tipo de características, como `numerical` o `categorical`. Se usa `None` si no se especifica.\n",
    "- **gamma**: Controla la complejidad del árbol. Un valor mayor de `gamma` reduce el sobreajuste, pero puede disminuir la capacidad de ajuste. Si es `None`, el valor predeterminado será utilizado.\n",
    "- **grow_policy**: Establece la política de crecimiento del árbol, como `depthwise` o `lossguide`. Si es `None`, se selecciona el valor predeterminado.\n",
    "- **importance_type**: Método para calcular la importancia de las características. Puede ser `weight`, `gain` o `cover`. Deja este parámetro como `None` si no es necesario modificarlo.\n",
    "- **interaction_constraints**: Especifica restricciones sobre cómo las características pueden interactuar. Si es `None`, no se aplican restricciones.\n",
    "- **learning_rate**: Tasa de aprendizaje para el modelo. Un valor más bajo aumenta la precisión, pero también requiere más estimadores. Si se deja como `None`, se utiliza el valor predeterminado.\n",
    "- **max_bin**: El número máximo de bins para discretizar las características. Si es `None`, se utilizará el valor predeterminado.\n",
    "- **max_cat_threshold**: Límite para el número máximo de categorías que pueden ser manejadas como una sola característica. Se utiliza `None` si no se necesita ajustar este parámetro.\n",
    "- **max_cat_to_onehot**: Limita la cantidad de categorías a transformar en una codificación One-Hot. Este valor se ajusta en función de los datos y no se cambia a menos que sea necesario.\n",
    "- **max_delta_step**: Ayuda en problemas de desbalanceo en el modelo. Si es `None`, se utilizará el valor predeterminado.\n",
    "- **max_depth**: Profundidad máxima de los árboles. Valores más altos permiten mayor complejidad, pero también mayor riesgo de sobreajuste. Si es `None`, se usará el valor predeterminado.\n",
    "- **max_leaves**: Número máximo de hojas por árbol. Este parámetro ayuda a controlar la complejidad del modelo.\n",
    "- **min_child_weight**: Peso mínimo requerido en un nodo hoja. Ayuda a controlar el sobreajuste y establece un umbral para la cantidad mínima de datos en una hoja.\n",
    "- **missing**: Valor a utilizar para representar los valores faltantes. Se usa `nan` por defecto.\n",
    "- **monotone_constraints**: Permite especificar restricciones monótonas para las características, si se necesita imponer alguna restricción. Si no, se deja como `None`.\n",
    "- **multi_strategy**: Estrategia para manejar múltiples clases en problemas multicategoría. Si es `None`, no se utiliza.\n",
    "- **n_estimators**: Número de árboles a construir. Un mayor número de árboles puede mejorar la precisión, pero también incrementa el tiempo de entrenamiento.\n",
    "- **n_jobs**: Número de núcleos que se usan para entrenar el modelo en paralelo. Si es `None`, se seleccionará el valor por defecto.\n",
    "- **num_parallel_tree**: Número de árboles que se construyen en paralelo en cada iteración. Si es `None`, no se utiliza este parámetro.\n",
    "- **random_state**: Establece una semilla para asegurar que los resultados sean reproducibles. Si es `None`, se usa un valor aleatorio.\n",
    "- **reg_alpha**: Término de regularización L1, que penaliza los coeficientes de las características menos importantes para evitar el sobreajuste.\n",
    "- **reg_lambda**: Término de regularización L2, útil para reducir el sobreajuste penalizando los coeficientes grandes.\n",
    "- **sampling_method**: Método de muestreo para entrenar el modelo. Si se deja como `None`, se selecciona el valor predeterminado.\n",
    "- **scale_pos_weight**: Ajuste para desbalanceo en el dataset, usado principalmente en problemas de clasificación. Se deja como `None` para regresión.\n",
    "- **subsample**: Proporción de datos a usar en cada árbol. Un valor menor puede ayudar a reducir el sobreajuste.\n",
    "- **tree_method**: Método utilizado para construir el árbol, como `auto`, `exact`, `approx`, entre otros. Si es `None`, se usa el valor predeterminado.\n",
    "- **validate_parameters**: Si es `True`, valida los parámetros antes de entrenar el modelo. Si es `None`, no se valida.\n",
    "- **verbosity**: Controla el nivel de salida de información durante el entrenamiento del modelo. Si es `None`, se usa el valor predeterminado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = XGBRegressor()\n",
    "\n",
    "hiperparametros = random_forest.get_params()\n",
    "\n",
    "for clave, valor in hiperparametros.items():\n",
    "    print(f\"{clave}: {valor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Randomized Search con **XGBRegressor**\n",
    "\n",
    "La **búsqueda aleatoria** o **Randomized Search** es un método de optimización de hiperparámetros que selecciona combinaciones de valores de manera aleatoria dentro de un espacio de hiperparámetros definido.\n",
    "\n",
    "En este caso, se realizaron **100 iteraciones**. Durante el ajuste de los hiperparámetros, se redujo la complejidad del modelo seleccionando únicamente los valores más relevantes. Esto se debe a que, en algunos casos, incrementar ciertos parámetros no solo no mejoraba las predicciones, sino que incluso empeoraba las métricas.\n",
    "\n",
    "Se inicia la búsqueda de los mejores hiperparámetros mediante **Randomized Search**, utilizando un rango amplio para abarcar diversas configuraciones del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para almacenamiento de resultados\n",
    "resultados_finales = []\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a optimizar\n",
    "modelo = XGBRegressor(random_state=42)\n",
    "\n",
    "parametros = {\n",
    "    \"booster\": [\"gbtree\"],  # Tipos de boosting disponibles en XGBoost\n",
    "    \"n_estimators\": randint(50, 1501),  # Número de árboles (entre 50 y 1500)\n",
    "    \"learning_rate\": uniform(0.01, 0.3),  # Tasa de aprendizaje, entre 0.01 y 0.3\n",
    "    \"max_depth\": randint(3, 16),  # Profundidad máxima de los árboles (entre 3 y 15)\n",
    "    \"gamma\": uniform(0.0, 0.5),  # Reducción mínima de pérdida en una división\n",
    "    \"subsample\": uniform(0.5, 0.5),  # Submuestreo de filas (entre 0.5 y 1.0)\n",
    "    \"colsample_bytree\": uniform(0.5, 0.5),  # Submuestreo de columnas (entre 0.5 y 1.0)\n",
    "    \"objective\": [\"reg:squarederror\"],  # Función de pérdida para regresión\n",
    "    \"tree_method\": [\"auto\"],\n",
    "    \"base_score\": uniform(0.3, 0.5),  # Centrado alrededor de 0.512 (rango 0.4 a 0.6)\n",
    "    \"max_leaves\": randint(40, 100),  # Valores alrededor de 62 (rango 50 a 75)\n",
    "}\n",
    "\n",
    "\n",
    "rmsle_calificador = make_scorer(root_mean_squared_log_error, greater_is_better=False)  \n",
    "\n",
    "# Usar RandomizedSearchCV para optimizar los hiperparámetros (como ya se han encontrado los hiperparámetros óptimos se reduce n_iter de 50 a 1)\n",
    "random_search = RandomizedSearchCV(estimator=modelo, param_distributions=parametros, n_iter=50, cv=kf, scoring=rmsle_calificador, n_jobs=-1)\n",
    "\n",
    "\n",
    "# Evaluar el modelo con validación cruzada\n",
    "resultados_modelo = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train = (y.iloc[train_index] + 1).apply(np.log)\n",
    "    y_val = (y.iloc[val_index] + 1).apply(np.log)\n",
    "\n",
    "    # Ajustar el modelo con los mejores hiperparámetros encontrados\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Obtener el mejor modelo después de la búsqueda\n",
    "    mejor_modelo = random_search.best_estimator_\n",
    "\n",
    "    # Hacer predicciones con el mejor modelo\n",
    "    yhat = mejor_modelo.predict(X_val)\n",
    "\n",
    "    # Invertir logaritmo de las predicciones\n",
    "    yhat = np.exp(yhat) - 1\n",
    "    y_val = np.exp(y_val) - 1\n",
    "\n",
    "    # Llamar a la función calcular_metricas_rendimiento\n",
    "    df_metricas = calcular_metricas_rendimiento(modelo, X_val, y_val, yhat)\n",
    "\n",
    "    # Extraer las métricas desde el DataFrame devuelto\n",
    "    r2, mae, rmse, mse, rmsle = df_metricas.iloc[0, 1:].values\n",
    "\n",
    "    resultados_modelo.append([modelo.__class__.__name__, r2, mae, rmse, mse, rmsle])\n",
    "\n",
    "# Guardar resultados del modelo\n",
    "resultados_finales.extend(resultados_modelo)\n",
    "\n",
    "# Convertir resultados a DataFrame para mejor visualización\n",
    "resultados_df = pd.DataFrame(resultados_finales, columns=['Modelo', 'R2', 'MAE', 'RMSE', 'MSE', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ordena el DataFrame por la columna 'RMSLE' de menor a mayor\n",
    "resultados_df_randomized_search = resultados_df.sort_values(by='RMSLE')\n",
    "\n",
    "resultados_df_randomized_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_parametros_randomized = random_search.best_params_\n",
    "print(\"Mejores hiperparámetros elegidos:\")\n",
    "for key, value in mejores_parametros_randomized.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search con **RandomForestRegressor**\n",
    "\n",
    "El método de Grid Search evalúa de manera exhaustiva todas las combinaciones posibles de un conjunto definido de hiperparámetros. Este proceso se realiza tras una búsqueda inicial más amplia utilizando **RandomizedSearchCV**, lo que permite refinar los resultados y seleccionar los hiperparámetros óptimos para el modelo **RandomForestRegressor**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar para almacenamiento de resultados\n",
    "resultados_finales = []\n",
    "\n",
    "# Configuración de validación cruzada\n",
    "# Cambio de 10 a 5\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Definir el modelo y los hiperparámetros a optimizar\n",
    "modelo = XGBRegressor(random_state=42)\n",
    "\n",
    "# Rango de hiperparámetros que se van a probar\n",
    "parametros_grid = {\n",
    "    'base_score': [0.39, 0.4049, 0.42], \n",
    "    'colsample_bytree': [0.52, 0.5349, 0.55], \n",
    "    'gamma': [0.009, 0.0111, 0.013], \n",
    "    'learning_rate': [0.02, 0.0223, 0.025], \n",
    "    'max_depth': [11, 12, 13], \n",
    "    'max_leaves': [50, 53, 56], \n",
    "    'n_estimators': [420, 439, 460],\n",
    "    'subsample': [0.58, 0.5992, 0.62] \n",
    "}\n",
    "\n",
    "# Función para calcular RMSLE\n",
    "def rmsle(y_val, yhat):\n",
    "    return root_mean_squared_log_error(y_val, yhat)\n",
    "\n",
    "# Convertir la función RMSLE a un scorer de scikit-learn\n",
    "rmsle_calificador = make_scorer(rmsle, greater_is_better=False)\n",
    "\n",
    "# Usar GridSearchCV para optimizar los hiperparámetros\n",
    "grid_search = GridSearchCV(estimator=modelo, param_grid=parametros_grid, cv=kf, scoring=rmsle_calificador, n_jobs=-1)\n",
    "\n",
    "# Aplicar logaritmo a las columnas seleccionadas\n",
    "y_log = (y + 1).apply(np.log)\n",
    "\n",
    "# Ajustar el modelo con los mejores hiperparámetros encontrados\n",
    "grid_search.fit(X, y_log)\n",
    "\n",
    "# Obtener el mejor modelo después de la búsqueda\n",
    "mejor_modelo = grid_search.best_estimator_\n",
    "\n",
    "# Hacer predicciones usando el modelo optimizado\n",
    "yhat_log = mejor_modelo.predict(X)\n",
    "yhat = np.exp(yhat_log) - 1\n",
    "y_val = np.exp(y_log) - 1\n",
    "\n",
    "# Llamar a la función calcular_metricas_rendimiento\n",
    "df_metricas = calcular_metricas_rendimiento(mejor_modelo, X, y_val, yhat)\n",
    "\n",
    "# Extraer las métricas desde el DataFrame devuelto\n",
    "r2, mae, rmse, mse, rmsle = df_metricas.iloc[0, 1:].values\n",
    "resultados_finales.append([mejor_modelo.__class__.__name__, r2, mae, rmse, mse, rmsle])\n",
    "\n",
    "# Convertir resultados a DataFrame para mejor visualización\n",
    "resultados_df = pd.DataFrame(resultados_finales, columns=['Modelo', 'R2', 'MAE', 'RMSE', 'MSE', 'RMSLE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se ordena el DataFrame por la columna 'RMSLE' de menor a mayor\n",
    "resultados_df_grid_search = resultados_df.sort_values(by='RMSLE')\n",
    "resultados_df_grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_parametros_grid_search = grid_search.best_params_\n",
    "print(\"Mejores hiperparámetros elegidos:\")\n",
    "for key, value in mejores_parametros_grid_search.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMBIAR EL TEXTO DE PREDICCIONES\n",
    "# X\n",
    "# ojo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de las Predicciones\n",
    "\n",
    "Comparación de las predicciones generadas `yhat` con los valores reales `y_val` de Grid Search.\n",
    "\n",
    "El modelo parece tener un buen rendimiento en términos generales, con predicciones bastante cercanas a los valores reales, especialmente en las métricas de media, mediana y percentiles.\n",
    "\n",
    "Presenta sesgos en las predicciones, subestima valores altos y bajos, no alcanzan los valores reales. Esto sugiere que, aunque el modelo sigue bien la tendencia general de los datos, no captura correctamente las variaciones extremas de los precios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabla_predicciones = pd.DataFrame({\n",
    "    'Valores Reales': y_val, \n",
    "    'Predicciones': yhat})\n",
    "\n",
    "tabla_predicciones.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features más importantes \n",
    "\n",
    "También se realizó un análisis de las importancias de las características para ver cuáles eran las más relevantes y cuáles menos para la predicción del precio de las casas.\n",
    "Se eliminaron características poco relevantes y se mejoró el preprocesamiento y encoding de las más importantes, aumentando la precisión del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances(modelo, X, top_n=20, ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features menos importantes\n",
    "\n",
    "Las características se ordenan de forma ascendente para identificar las menos relevantes. Esto facilita el análisis de las variables con menor influencia en las predicciones del modelo y permite valorar su posible eliminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances(modelo, X, top_n=20, ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAMBIAR EL TEXTO DE CURVA APRENDIZAJE\n",
    "# X\n",
    "# ojo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis de la Curva de Aprendizaje\n",
    "\n",
    "En el análisis de la curva de aprendizaje del mejor modelo de validación cruzada, se observó que el modelo parece generalizar bastante bien, ya que la brecha entre las curvas de entrenamiento y validación no es alarmante. Ambas curvas se estabilizan, lo que sugiere que el modelo ha alcanzado un punto donde no está sobreajustado (overfitting). Aunque el modelo generaliza bien, el RMSLE en el conjunto de validación (curva verde) es más alto que en el conjunto de entrenamiento, lo que indica que el modelo podría beneficiarse de ajustes adicionales en algunos de sus hiperparámetros para mejorar el rendimiento en datos no vistos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graficar_curva_aprendizaje_rmsle(modelo, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelo Final: **XGBRegressor**\n",
    "\n",
    "Aplicación de Hiperparámetros al Conjunto de Test. En el proceso de ajuste de hiperparámetros, se redujo la complejidad del modelo seleccionando únicamente los valores más relevantes para mejorar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga de los datos de entrenamiento y prueba desde archivos pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train= pd.read_pickle('../data/train.pkl')\n",
    "test= pd.read_pickle('../data/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(columns=columnas_eliminar, inplace=True)\n",
    "test.drop(columns=columnas_eliminar, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separación las características (X) y la variable objetivo (y) para el conjunto de entrenamiento, eliminando las columnas `SalePrice` e `Id` de `X_train` y asignando `SalePrice` a `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(['SalePrice', 'Id'], axis=1)  \n",
    "y_train = train['SalePrice']  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guarda la columna `Id` antes de eliminarla para luego guardar las predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids = test['Id'].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea **`X_test`** sin la columna `Id` para el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test.drop(['SalePrice', 'Id'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se aplica la transformación logarítmica a la target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.log1p(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se definieron los parámetros del modelo y se procedió a entrenarlo. Antes de aplicar los mejores hiperparámetros obtenidos a través de **Grid Search**, se realizó un ajuste manual final para optimizar aún más el rendimiento del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parametros = {\n",
    "    'base_score': 0.4049,  \n",
    "    'booster': 'gbtree',\n",
    "    'learning_rate': 0.0223,  \n",
    "    'max_depth': 12,  \n",
    "    'max_leaves': 53, \n",
    "    'n_estimators': 439,  \n",
    "    'subsample': 0.5992, \n",
    "    'objective': 'reg:squarederror',\n",
    "    'colsample_bytree': 0.5349, \n",
    "    'gamma': 0.0111, \n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "modelo = XGBRegressor(**parametros, random_state=42)\n",
    "\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "yhat = modelo.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reversión de la transformación logarítmica para SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = np.expm1(yhat)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF de las predicciones\n",
    "\n",
    "Después de realizar un ciclo iterativo de modelado, en el cual se limpiaron variables, se ajustaron los parámetros del modelo y se mejoró el rendimiento predictivo, se procede a crear un DF de **Submission** con los identificadores de las instancias de prueba y sus respectivas predicciones de precios. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicciones = pd.DataFrame({\n",
    "    'Id': test_ids,  \n",
    "    'SalePrice': predicciones\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación Estadística entre Predicciones y Entrenamiento\n",
    "\n",
    "Las predicciones del modelo están bastante cerca de los valores reales, con algunas pequeñas diferencias:\n",
    "\n",
    "- **Promedio**: Las predicciones tienen un promedio de **177,613.95**, ligeramente por debajo de los valores reales (**180,921.20**).\n",
    "- **Desviación Estándar**: Las predicciones tienen una desviación estándar de **74,106.54**, menor que la de los valores reales (**79,442.50**), indicando menos dispersión.\n",
    "- **Percentiles**: \n",
    "  - 25%: Predicciones (**129,844.17**) vs Reales (**129,975.00**).\n",
    "  - 50% (Mediana): Predicciones (**156,468.75**) vs Reales (**163,000.00**).\n",
    "  - 75%: Predicciones (**206,565.28**) vs Reales (**214,000.00**).\n",
    "- **Máximo**: El valor máximo de las predicciones es **531,618.56**, mientras que el valor máximo real es **755,000.00**, indicando que el modelo tiene dificultades con los valores más altos.\n",
    "\n",
    "En resumen, las predicciones son bastante cercanas a los valores reales, pero hay margen de mejora en los valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisar_predicciones(predicciones, test_ids, df_predicciones, train=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se guardan las predicciones generadas por el modelo en un archivo CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predicciones.to_csv('../outputs/predicciones_XGBRegressor.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Mejor puntuacion kaggle](../docs/kaggle_puntuacion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones **XGBRegressor** \n",
    "\n",
    "Los resultados obtenidos con **XGBRegressor** en este nuevo enfoque muestran que este modelo ha logrado un rendimiento excepcional. La nueva puntuación de **0.12842** ha permitido alcanzar la **posición 608** en la competición de Kaggle, lo que representa una mejora significativa.  \n",
    "\n",
    "Este modelo no solo optimiza el **RMSLE**, sino que también demuestra una alta precisión en la predicción de los valores más altos de **SalePrice**, un aspecto crucial en esta competencia. La combinación de validación cruzada y un enfoque en valores extremos ha consolidado a **XGBoost** como la mejor opción para este conjunto de datos.  \n",
    "\n",
    "Cabe destacar que las mejores puntuaciones en este reto corresponden a modelos con valores de **0.00000** o **0.00044**, lo que indica que predicen casi perfectamente este conjunto de datos. Sin embargo, estos modelos probablemente no generalicen bien a datos similares fuera de la competición, ya que es posible que su rendimiento se degrade en escenarios distintos.  \n",
    "\n",
    "Si bien aún hay margen para mejoras, este resultado demuestra un avance importante y refuerza la idea de que un enfoque meticuloso en la selección de características y el ajuste de hiperparámetros puede marcar una gran diferencia en la competición. Se continuará explorando nuevas estrategias para seguir optimizando el modelo y mejorar su capacidad de generalización.  \n",
    "\n",
    "Opciones posibles futuras de exploración:\n",
    "- **Agregar una nueva columna del precio por metro cuadrado.**\n",
    "- Realizar una búsqueda fina con **Bayesian Optimization** o ajustar manualmente un poco más."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
